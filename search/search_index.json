{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AGNBoost","text":"<p>A powerful machine learning toolkit for astronomical data analysis using advanced XGBoost techniques.</p>"},{"location":"#overview","title":"Overview","text":"<p>AGNBoost is a specialized Python framework designed for astronomers working with photometric data. Built on the foundation of XGBoostLSS, AGNBoost provides a streamlined workflow for disitrubtional regression with photometric data, with particular focus on Active Galactic Nuclei (AGN) identification and galaxy property estimation.</p> <p>Quick Start</p> <p>New to AGNBoost? Check out our Quick Start Guide to get up and running in minutes!</p>"},{"location":"#core-features","title":"Core Features","text":""},{"location":"#astronomy-focused-data-management","title":"\ud83d\udd2d Astronomy-Focused Data Management","text":"<ul> <li>Smart Catalog System: Load and manage astronomical data from FITS files, CSV, or pandas DataFrames</li> <li>Band Configuration: Flexible JSON-based configuration for photometric bands with metadata (wavelengths, shorthand names)</li> <li>Automatic Feature Engineering: Built-in color calculations, magnitude transformations, and signal-to-noise filtering</li> <li>Data Validation: Ensures data quality and compatibility across different datasets</li> </ul>"},{"location":"#convenient-pipeline","title":"\ud83d\ude80 Convenient Pipeline","text":"<ul> <li>Hyperparameter Optimization: Intelligent tuning with custom parameter grids and early stopping</li> <li>Cross-Validation: Robust model validation with stratified splitting for both classification and regression</li> <li>Model Persistence: Comprehensive saving and loading with full metadata tracking</li> </ul>"},{"location":"#xgboostlss-integration","title":"\u26a1 XGBoostLSS Integration","text":"<ul> <li>Distributional Modeling: Go beyond point estimates with full probability distributions</li> <li>Custom Objectives: Specialized loss functions for astronomical applications</li> <li>Efficient Training: Optimized for large astronomical datasets with GPU acceleration support</li> <li>Uncertainty Quantification: Robust uncertainty estimates for Astronomical analysis</li> </ul>"},{"location":"#research-ready-tools","title":"\ud83d\udee0 Research-Ready Tools","text":"<ul> <li>Flexible Data Splitting:  Train/validation/test splits with optional stratification</li> <li>Signal-to-Noise Filtering: Built-in S/N cuts for photometric data quality control</li> <li>Transform Pipeline: Easy-to-use data transformation and augmentation tools</li> <li>Extensible Architecture: Designed for customization and integration with existing workflows</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p>We recommend using a virtual environment to manage dependencies. AGNBoost works best with Python 3.10/3.11 or later.</p>"},{"location":"#using-conda-recommended","title":"Using Conda (Recommended)","text":"<pre><code># Create a new conda environment\nconda create -n agnboost python=3.11\nconda activate agnboost\n\n# Clone the repository\ngit clone https://github.com/yourusername/agnboost.git\ncd agnboost\n\n# Install in development mode\npip install -e .\n</code></pre>"},{"location":"#using-pip-and-venv","title":"Using pip and venv","text":"<pre><code># Create a virtual environment\npython -m venv agnboost-env\nsource agnboost-env/bin/activate  # On Windows: agnboost-env\\Scripts\\activate\n\n# Clone and install\ngit clone https://github.com/yourusername/agnboost.git\ncd agnboost\npip install -e .\n</code></pre>"},{"location":"#verify-installation","title":"Verify Installation","text":"<pre><code>import agnboost\nfrom agnboost import Catalog, AGNBoost\n\nprint(f\"AGNBoost version: {agnboost.__version__}\")\n</code></pre> <p>Development Installation</p> <p>The <code>-e</code> flag installs AGNBoost in \"editable\" mode, which means changes to the source code will be immediately available without reinstalling. This is particularly useful if you plan to contribute to the project or customize it for your research.</p>"},{"location":"#built-on-xgboostlss","title":"Built on XGBoostLSS","text":"<p>AGNBoost leverages the power of XGBoostLSS, a cutting-edge extension of XGBoost that enables distributional modeling. Instead of predicting single point estimates, XGBoostLSS models the entire conditioan distributions, providing:</p> <ul> <li>Full Distributional Predictions: Estimate not just the mean, but the entire shape of the target distribution</li> <li>Robust Uncertainty Quantification: Get principled uncertainty estimates for your astronomical measurements  </li> <li>Flexible Distributions: Choose from a wide variety of probability distributions tailored to your data</li> <li>Advanced Regularization: Built-in techniques to prevent overfitting and improve generalization</li> </ul> <p>This makes AGNBoost particularly powerful for astronomical applications where uncertainty quantification is crucial, such as:</p> <ul> <li>Photometric redshift estimation with confidence intervals</li> <li>AGN identification with uncertainty bounds</li> <li>Stellar mass estimation with full posterior distributions</li> </ul>"},{"location":"#whats-next","title":"What's Next?","text":"<ul> <li> <p>Getting Started</p> <p>New to AGNBoost? Start with our comprehensive tutorial covering installation, basic usage, and your first analysis.</p> <p>Quick Start \u2192</p> </li> <li> <p>Tutorials</p> <p>Step-by-step guides covering everything from basic usage to advanced training pipelines.</p> <p>View Tutorials \u2192</p> </li> <li> <p>API Reference</p> <p>Complete documentation of all classes, methods, and functions in AGNBoost.</p> <p>API Docs \u2192</p> </li> </ul>"},{"location":"#community-and-support","title":"Community and Support","text":"<p>AGNBoost is developed by astronomers, for astronomers. We welcome contributions, feedback, and collaboration from the community.</p> <ul> <li>GitHub Repository: https://github.com/hamblin-ku/AGNBoost</li> <li>Issues and Discussions: Use GitHub Issues for bug reports and feature requests</li> <li>Contributing: See our Contributing Guide to get involved</li> </ul> <p>AGNBoost is open-source software released under the MIT License. If you use AGNBoost in your research, please see our Citation Guide.</p>"},{"location":"api/","title":"API Reference","text":"<p>This page provides complete documentation for all AGNBoost classes and functions.</p>"},{"location":"api/#overview","title":"Overview","text":"<p>AGNBoost consists of two main classes:</p> <ul> <li>Catalog: For data loading, management, and feature engineering</li> <li>AGNBoost: For machine learning model training, tuning, and prediction</li> </ul>"},{"location":"api/#catalog-class","title":"Catalog Class","text":"<p>The <code>Catalog</code> class is your entry point for working with astronomical data. It handles loading data from various formats, validates photometric bands, creates features, and manages data splits.</p>"},{"location":"api/#key-features","title":"Key Features","text":"<ul> <li>Load FITS files, CSV files, or pandas DataFrames</li> <li>Automatic photometric band validation</li> <li>Feature engineering (colors, transformations)</li> <li>Train/validation/test data splitting</li> <li>Signal-to-noise filtering</li> </ul> <p>A class for loading, managing, and manipulating astronomical data.</p> <p>The Catalog class provides tools for loading astronomical data from various formats, performing feature engineering, data validation, and preparing data for machine learning workflows. It supports FITS files, CSV files, and pandas DataFrames.</p> <p>Attributes:</p> Name Type Description <code>data</code> <code>DataFrame</code> <p>The main astronomical dataset.</p> <code>features_df</code> <code>DataFrame</code> <p>Engineered features for machine learning.</p> <code>valid_columns</code> <code>dict</code> <p>Metadata for validated photometric band columns.</p> <code>train_indices</code> <code>Index</code> <p>Indices for training data split.</p> <code>val_indices</code> <code>Index</code> <p>Indices for validation data split.</p> <code>test_indices</code> <code>Index</code> <p>Indices for test data split.</p> <p>Examples:</p> <p>Basic usage with a FITS file:</p> <pre><code>from agnboost import Catalog\n\n# Load data\ncatalog = Catalog(path=\"jwst_data.fits\")\n\n# Create features\ncatalog.create_feature_dataframe()\n\n# Split data\ncatalog.split_data(test_size=0.2, val_size=0.2)\n</code></pre> <p>Loading data from a pandas DataFrame:</p> <p>```python import pandas as pd df = pd.read_csv(\"data.csv\") catalog = Catalog(data=df) '''</p>"},{"location":"api/#agnboost.dataset.Catalog.create_color_dataframe","title":"create_color_dataframe  <code>staticmethod</code>","text":"<pre><code>create_color_dataframe(data, bands)\n</code></pre> <p>Calculate photometric colors from band fluxes.</p>"},{"location":"api/#agnboost.dataset.Catalog.create_color_dataframe--returns","title":"Returns:","text":"<p>pandas.DataFrame     DataFrame containing color columns.</p>"},{"location":"api/#agnboost.dataset.Catalog.create_feature_dataframe","title":"create_feature_dataframe","text":"<pre><code>create_feature_dataframe(feature_funcs=None)\n</code></pre> <p>Create a dataframe of features for eventual use with AGNBoost class.</p>"},{"location":"api/#agnboost.dataset.Catalog.create_feature_dataframe--parameters","title":"Parameters:","text":"<p>feature_funcs : list or None     List of functions to apply to the validated columns. If None,     default features (log10 of bands, colors, and square of colors) are created.</p>"},{"location":"api/#agnboost.dataset.Catalog.create_feature_dataframe--returns","title":"Returns:","text":"<p>pandas.DataFrame     The created feature dataframe (also stored as self.features_df).</p>"},{"location":"api/#agnboost.dataset.Catalog.transform","title":"transform","text":"<pre><code>transform(column_name, transform_func, new_column_name=None, inplace=False)\n</code></pre> <p>Apply a transformation function to a column and save the result.</p>"},{"location":"api/#agnboost.dataset.Catalog.transform--parameters","title":"Parameters:","text":"<p>column_name : str     Name of the column to transform. transform_func : callable     Function to apply to the column. new_column_name : str or None, default=None     Name for the transformed column. If None and not inplace, will use     f\"{column_name}_transformed\". inplace : bool, default=False     If True, overwrite the original column. If False, create a new column.</p>"},{"location":"api/#agnboost.dataset.Catalog.transform--returns","title":"Returns:","text":"<p>pandas.Series     The transformed column.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_targets","title":"get_targets","text":"<pre><code>get_targets(target_names)\n</code></pre> <p>Extract target columns from the data.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_targets--parameters","title":"Parameters:","text":"<p>target_names : str or list     Name(s) of target column(s) to extract. drop_na : bool, default=False     If True, drop rows with NA values in any of the target columns.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_targets--returns","title":"Returns:","text":"<p>pandas.DataFrame or pandas.Series     Target column(s). Returns a Series if a single target name is provided,     or a DataFrame if multiple targets are requested.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_features","title":"get_features","text":"<pre><code>get_features()\n</code></pre> <p>Get the feature dataframe, creating it if it doesn't exist.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_features--returns","title":"Returns:","text":"<p>pandas.DataFrame     The feature dataframe.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_feature_names","title":"get_feature_names","text":"<pre><code>get_feature_names()\n</code></pre> <p>Get the feature names dataframe, creating it if it doesn't exist.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_feature_names--returns","title":"Returns:","text":"<p>pandas.DataFrame     The feature dataframe.</p>"},{"location":"api/#agnboost.dataset.Catalog.print_data_summary","title":"print_data_summary","text":"<pre><code>print_data_summary()\n</code></pre> <p>Print a formatted summary of the loaded data.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_valid_bands","title":"get_valid_bands","text":"<pre><code>get_valid_bands()\n</code></pre> <p>Get information about valid band columns in the data.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_valid_bands--returns","title":"Returns:","text":"<p>dict     Dictionary of valid band columns with their metadata.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_valid_bands_list","title":"get_valid_bands_list","text":"<pre><code>get_valid_bands_list()\n</code></pre> <p>Get information about valid band columns in the data.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_valid_bands_list--returns","title":"Returns:","text":"<p>dict     Dictionary of valid band columns with their metadata.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_band_wavelengths","title":"get_band_wavelengths","text":"<pre><code>get_band_wavelengths()\n</code></pre> <p>Get a dictionary mapping band columns to their wavelengths.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_band_wavelengths--returns","title":"Returns:","text":"<p>dict     Dictionary mapping column names to wavelengths in microns.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_band_shorthands","title":"get_band_shorthands","text":"<pre><code>get_band_shorthands()\n</code></pre> <p>Get a dictionary mapping band columns to their shorthand names.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_band_shorthands--returns","title":"Returns:","text":"<p>dict     Dictionary mapping column names to shorthand identifiers.</p>"},{"location":"api/#agnboost.dataset.Catalog.sn_cut","title":"sn_cut","text":"<pre><code>sn_cut(columns=None, threshold=3.0, inplace=False, suffix='_err')\n</code></pre> <p>Perform a signal-to-noise ratio cut on the specified columns.</p>"},{"location":"api/#agnboost.dataset.Catalog.sn_cut--parameters","title":"Parameters:","text":"<p>columns : dict or None     Dictionary mapping value columns to their error columns.     Example: {'flux': 'flux_err', 'redshift': 'redshift_err'}     If None, automatically detect band columns and use {band: band+suffix} pairs. threshold : float, default=3.0     Minimum S/N ratio to keep a row. inplace : bool, default=False     If True, modifies the data in place; otherwise, returns a copy. suffix : str, default='_err'     Suffix to append to band names to find error columns, if columns=None.</p>"},{"location":"api/#agnboost.dataset.Catalog.sn_cut--returns","title":"Returns:","text":"<p>pandas.DataFrame or None     Filtered dataframe if inplace=False, otherwise None.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_data","title":"get_data","text":"<pre><code>get_data()\n</code></pre> <p>Return the loaded dataframe.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_data--returns","title":"Returns:","text":"<p>pandas.DataFrame     The loaded data.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_columns","title":"get_columns","text":"<pre><code>get_columns()\n</code></pre> <p>Return the column names of the loaded dataframe.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_columns--returns","title":"Returns:","text":"<p>list     List of column names.</p>"},{"location":"api/#agnboost.dataset.Catalog.filter_data","title":"filter_data","text":"<pre><code>filter_data(filter_conditions)\n</code></pre> <p>Filter the data based on provided conditions.</p>"},{"location":"api/#agnboost.dataset.Catalog.filter_data--parameters","title":"Parameters:","text":"<p>filter_conditions : dict     Dictionary of column:value pairs to filter on.</p>"},{"location":"api/#agnboost.dataset.Catalog.filter_data--returns","title":"Returns:","text":"<p>pandas.DataFrame     Filtered dataframe.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_subset","title":"get_subset","text":"<pre><code>get_subset(columns=None, rows=None)\n</code></pre> <p>Get a subset of the data by columns and/or rows.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_subset--parameters","title":"Parameters:","text":"<p>columns : list or None     List of column names to include. If None, includes all columns. rows : slice, list, or None     Rows to include. Can be a slice (e.g., slice(0, 100)), a list of indices,     or None to include all rows.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_subset--returns","title":"Returns:","text":"<p>pandas.DataFrame     Subset of the data.</p>"},{"location":"api/#agnboost.dataset.Catalog.save_to_csv","title":"save_to_csv","text":"<pre><code>save_to_csv(output_path, index=False)\n</code></pre> <p>Save the current data to a CSV file.</p>"},{"location":"api/#agnboost.dataset.Catalog.save_to_csv--parameters","title":"Parameters:","text":"<p>output_path : str     Path to save the CSV file. index : bool, default=False     Whether to include the index in the saved file.</p>"},{"location":"api/#agnboost.dataset.Catalog.save_to_csv--returns","title":"Returns:","text":"<p>bool     True if successful, False otherwise.</p>"},{"location":"api/#agnboost.dataset.Catalog.drop_nan","title":"drop_nan","text":"<pre><code>drop_nan(columns=None, inplace=False, how='any')\n</code></pre> <p>Drop rows with NaN values in specified columns or validated columns.</p>"},{"location":"api/#agnboost.dataset.Catalog.drop_nan--parameters","title":"Parameters:","text":"<p>columns : list or None, default=None     List of column names to check for NaN. If None, uses all validated columns. inplace : bool, default=False     If True, performs operation in-place and returns None.     If False, returns a copy of the data with rows dropped. how : {'any', 'all'}, default='any'     'any' : Drop if any of the specified columns has NaN     'all' : Drop only if all of the specified columns have NaN</p>"},{"location":"api/#agnboost.dataset.Catalog.drop_nan--returns","title":"Returns:","text":"<p>pandas.DataFrame or None     The DataFrame with NaN rows dropped, or None if inplace=True.</p>"},{"location":"api/#agnboost.dataset.Catalog.split_data","title":"split_data","text":"<pre><code>split_data(test_size=0.2, val_size=0.2, random_state=None, stratify_col=None, n_bins=10)\n</code></pre> <p>Split the data into train, validation, and test sets.</p>"},{"location":"api/#agnboost.dataset.Catalog.split_data--parameters","title":"Parameters:","text":"<p>test_size : float, default=0.2     Proportion of the data to use for testing (0.0 to 1.0). val_size : float, default=0.2     Proportion of the data to use for validation (0.0 to 1.0). random_state : int or None, default=None     Random seed for reproducibility. stratify_col : str or None, default=None     Column name to use for stratified splitting. If provided,      ensures proportional representation of this column's values     in all splits. For continuous columns, binning will be applied. n_bins : int, default=10     Number of bins to use when stratifying on a continuous column.     Only used when stratify_col is a continuous variable.</p>"},{"location":"api/#agnboost.dataset.Catalog.split_data--returns","title":"Returns:","text":"<p>tuple     (train_indices, val_indices, test_indices) - Indices for each split</p>"},{"location":"api/#agnboost.dataset.Catalog.get_split_df","title":"get_split_df","text":"<pre><code>get_split_df(split_type='train', include_features=True, include_target=None, return_DMatrix=False, missing=np.nan)\n</code></pre> <p>Get a dataframe for the specified data split.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_split_df--parameters","title":"Parameters:","text":"<p>split_type : str, default='train'     Which data split to use. Options: 'train', 'val'/'validation', or 'test'. include_features : bool, default=True     If True, include the feature columns in the result. include_target : str, list, or None, default=None     Target column(s) to include. If None, no target columns are included. return_DMatrix: bool, default = False     Whether to return a XGBoost DMatrix instead of a pandas Dataframe. missing : int, float, or None, default=np.nan     Value to represent missing values in XGBoost.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_split_df--returns","title":"Returns:","text":"<p>pandas.DataFrame     DataFrame for the specified split with requested columns.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_train_val_test_sizes","title":"get_train_val_test_sizes","text":"<pre><code>get_train_val_test_sizes()\n</code></pre> <p>Get the sizes and percentages of the train, validation, and test sets.</p>"},{"location":"api/#agnboost.dataset.Catalog.get_train_val_test_sizes--returns","title":"Returns:","text":"<p>dict     Dictionary with set sizes and percentages.     Format: {         'total': int,         'train': {'size': int, 'percentage': float},         'validation': {'size': int, 'percentage': float},          'test': {'size': int, 'percentage': float}     }</p>"},{"location":"api/#agnboost-class","title":"AGNBoost Class","text":"<p>The <code>AGNBoost</code> class provides the machine learning functionality, including model training, hyperparameter tuning, and prediction with uncertainty quantification.</p>"},{"location":"api/#key-features_1","title":"Key Features","text":"<ul> <li>XGBoostLSS integration for distributional modeling</li> <li>Hyperparameter optimization</li> <li>Model persistence and loading</li> <li>Multi-target support</li> <li>Comprehensive logging and validation</li> </ul>"},{"location":"api/#agnboost.model.AGNBoost.tune_model","title":"tune_model","text":"<pre><code>tune_model(model_name, param_grid, dtune, split_type='train', max_minutes=10, nfold=2, early_stopping_rounds=100)\n</code></pre> <p>Tune hyperparameters for the specified model.</p>"},{"location":"api/#agnboost.model.AGNBoost.tune_model--parameters","title":"Parameters:","text":"<p>model_name : str     Name of the model to tune. Must be in self.model_names. param_grid : dict     Dictionary of hyperparameter ranges to search.     Example: {'max_depth': [3, 5, 7], 'learning_rate': [0.01, 0.1, 0.3]} dtune : xgboost.DMatrix or pandas.DataFrame or Catalog     Data to use for tuning. If DataFrame or Catalog, will be converted to DMatrix. max_minutes : int, default=10     Maximum duration for tuning in minutes. nfold : int, default=2     Number of cross-validation folds. early_stopping_rounds : int, default=100     Number of rounds without improvement before early stopping.</p>"},{"location":"api/#agnboost.model.AGNBoost.tune_model--returns","title":"Returns:","text":"<p>dict     Dictionary containing best parameters and tuning metrics.</p>"},{"location":"api/#agnboost.model.AGNBoost.train_model","title":"train_model","text":"<pre><code>train_model(model_name, dtrain, dval=None, params=None, split_type='train', num_boost_round=1000, early_stopping_rounds=None, verbose_eval=False, custom_objective=None, custom_metric=None)\n</code></pre> <p>Train an XGBoost model with the given parameters.</p>"},{"location":"api/#agnboost.model.AGNBoost.train_model--parameters","title":"Parameters:","text":"<p>model_name : str     Name of the model to train. Must be in self.model_names. dtrain : xgboost.DMatrix or Catalog     Training data. If a Catalog, will create a DMatrix using the specified split. dval : xgboost.DMatrix, bool, or None, default=None     Validation data. If a DMatrix, use directly.     If True and dtrain is a Catalog, create a validation DMatrix from the Catalog.     If False or None, no validation data is used. params : dict or None, default=None     Parameters for XGBoost. If None, uses tuned_params from model_info if available,     otherwise uses default parameters. split_type : str, default='train'     Which data split to use if dtrain is a Catalog. Options: 'train', 'val', 'test'. num_boost_round : int, default=1000     Number of boosting rounds. early_stopping_rounds : int or None, default=50     Number of rounds without improvement before early stopping.     If None, no early stopping is used. verbose_eval : int or bool, default=100     Controls XGBoost's logging frequency. If True, prints every round.     If int, prints every verbose_eval rounds. If False, no logging. custom_objective : callable or None, default=None     Custom objective function for XGBoost. custom_metric : callable or None, default=None     Custom evaluation metric for XGBoost.</p>"},{"location":"api/#agnboost.model.AGNBoost.train_model--returns","title":"Returns:","text":"<p>tuple     (trained_model, training_results)</p>"},{"location":"api/#agnboost.model.AGNBoost.load_model","title":"load_model","text":"<pre><code>load_model(file_name, overwrite=False)\n</code></pre> <p>Load pre-trained models from disk.</p>"},{"location":"api/#agnboost.model.AGNBoost.load_model--parameters","title":"Parameters:","text":"<p>model_names : list, str, or None, default=None     Name(s) of models to load. If None, loads all models in self.model_names. retrain : bool, default=False     If True, forces retraining even if models exist.</p>"},{"location":"api/#agnboost.model.AGNBoost.load_model--returns","title":"Returns:","text":"<p>bool     True if all requested model was loaded successfully, False otherwise.</p>"},{"location":"api/#agnboost.model.AGNBoost.predict","title":"predict","text":"<pre><code>predict(data, model_name, split_use=None, seed=123)\n</code></pre> <p>Make predictions using trained models.</p>"},{"location":"api/#agnboost.model.AGNBoost.predict--parameters","title":"Parameters:","text":"<p>data : DataFrame, Catalog, or dict     Data to make predictions on. Can be a pandas DataFrame, a Catalog object,     or a dict mapping model names to their specific data. model_name : str or None     If provided, use only this model. Otherwise, use all available models.</p>"},{"location":"api/#agnboost.model.AGNBoost.predict--returns","title":"Returns:","text":"<p>dict     Dictionary of predictions for each model.</p>"},{"location":"api/#agnboost.model.AGNBoost.model_uncertainty","title":"model_uncertainty  <code>staticmethod</code>","text":"<pre><code>model_uncertainty(model: model, data: DMatrix, dist_name: str, best_iter: int, M: int = 1, seed=123) -&gt; np.array\n</code></pre> <p>Function that predicts from the trained model.</p>"},{"location":"api/#agnboost.model.AGNBoost.model_uncertainty--arguments","title":"Arguments","text":"<p>model : xgblsslib.model     Trained model. data : xgb.DMatrix     Data to predict frmodel: xgblsslib.modelom. M   : int     Number of desired models in virtual ensemble.</p>"},{"location":"api/#agnboost.model.AGNBoost.model_uncertainty--returns","title":"Returns","text":"<p>pred : pd.DataFrame     Predictions.</p>"},{"location":"api/#agnboost.model.AGNBoost.predict_dist_trunc","title":"predict_dist_trunc  <code>staticmethod</code>","text":"<pre><code>predict_dist_trunc(dist: DistributionClass, booster: Booster, start_values: ndarray, data: DMatrix, iteration_range: Tuple[int, int] = (0, 0)) -&gt; pd.DataFrame\n</code></pre> <p>Function that predicts from therag trained model.</p>"},{"location":"api/#agnboost.model.AGNBoost.predict_dist_trunc--arguments","title":"Arguments","text":"<p>booster : xgb.Boosterdist     Trained model. start_values : np.ndarray     Starting values for each distributional parameter. data : xgb.DMatrix     Data to predict from. iteration_range: Tuple[int,int]     Which layer of trees to use for prediction in xgb.booster.predict</p>"},{"location":"api/#agnboost.model.AGNBoost.predict_dist_trunc--returns","title":"Returns","text":"<p>pred : pd.DataFrame     Predictions.xgboost model get numeber of boostin rounds</p>"},{"location":"api/#agnboost.model.AGNBoost.list_available_models","title":"list_available_models  <code>staticmethod</code>","text":"<pre><code>list_available_models(models_dir=None)\n</code></pre> <p>List all available pre-trained models in the models directory.</p>"},{"location":"api/#agnboost.model.AGNBoost.list_available_models--parameters","title":"Parameters:","text":"<p>models_dir : str or None     Directory to look for models. If None, uses the default models directory.</p>"},{"location":"api/#agnboost.model.AGNBoost.list_available_models--returns","title":"Returns:","text":"<p>dict     Dictionary with model names as keys and metadata as values.</p>"},{"location":"api/#utility-functions","title":"Utility Functions","text":"<p>Helper functions for data processing, feature engineering, and model management.</p>"},{"location":"api/#agnboost.utils.log_message","title":"log_message","text":"<pre><code>log_message(message, level='INFO')\n</code></pre> <p>Log a message with the specified level.</p>"},{"location":"api/#agnboost.utils.log_message--parameters","title":"Parameters:","text":"<p>message : str     Message to log. level : str     Log level (INFO, WARNING, ERROR).</p>"},{"location":"api/#agnboost.utils.validate_param_grid","title":"validate_param_grid","text":"<pre><code>validate_param_grid(param_grid)\n</code></pre> <p>Validate that the parameter grid is correctly formatted.</p> <p>Expected format: {     \"param_name\": [\"type\", type_specific_value],     ... }</p> <p>Where \"type\" is one of: - \"none\": type_specific_value should be a list of specific values - \"int\": type_specific_value should be a dict with \"low\", \"high\", \"log\" keys - \"float\": type_specific_value should be a dict with \"low\", \"high\", \"log\" keys - \"categorical\": type_specific_value should be a list of possible values</p>"},{"location":"api/#agnboost.utils.validate_param_grid--parameters","title":"Parameters:","text":"<p>param_grid : dict     Dictionary of parameter grid specifications</p>"},{"location":"api/#agnboost.utils.validate_param_grid--returns","title":"Returns:","text":"<p>tuple     (is_valid, error_message) - (True, None) if valid, (False, error_msg) if invalid</p>"},{"location":"api/#agnboost.utils.validate_param_dict","title":"validate_param_dict","text":"<pre><code>validate_param_dict(params)\n</code></pre> <p>Validate that the passed params are a dictionary of single values</p> <p>Expected format: {     \"param_name\": value,     ... }</p>"},{"location":"api/#agnboost.utils.validate_param_dict--parameters","title":"Parameters:","text":"<p>params : dict     Dictionary of parameter grid specifications</p>"},{"location":"api/#agnboost.utils.validate_param_dict--returns","title":"Returns:","text":"<p>tuple     (is_valid, error_message) - (True, None) if valid, (False, error_msg) if invalid</p>"},{"location":"getting-started/","title":"Getting Started","text":"<p>docs/getting-started.md: <pre><code># Quick Start\n\nThis guide will get you up and running with AGNBoost in just a few minutes.\n\n## Prerequisites\n\nMake sure you have Python 3.8 or later installed and AGNBoost is set up in your environment.\n\n```bash\n# Verify your installation\npython -c \"import agnboost; print('AGNBoost is ready!')\"\n</code></pre></p>"},{"location":"getting-started/#your-first-catalog","title":"Your First Catalog","text":"<p>The <code>Catalog</code> class is the starting point for working with astronomical data in AGNBoost.</p>"},{"location":"getting-started/#loading-data-from-a-file","title":"Loading Data from a File","text":"<pre><code>from agnboost import Catalog\n\n# Load data from a FITS file\ncatalog = Catalog(path=\"your_data.fits\")\n\n# Or from a CSV file\ncatalog = Catalog(path=\"your_data.csv\")\n\n# View basic information about your data\ncatalog.print_data_summary()\n</code></pre>"},{"location":"getting-started/#loading-data-from-a-dataframe","title":"Loading Data from a DataFrame","text":"<p>If you already have your data in a pandas DataFrame:</p> <pre><code>import pandas as pd\nfrom agnboost import Catalog\n\n# Load your data however you prefer\ndf = pd.read_csv(\"your_data.csv\")\n\n# Create a catalog from the DataFrame\ncatalog = Catalog(data=df)\n</code></pre>"},{"location":"getting-started/#working-with-features","title":"Working with Features","text":"<p>AGNBoost can automatically create features from your photometric data:</p> <pre><code># Generate features (colors, log magnitudes, etc.)\ncatalog.create_feature_dataframe()\n\n# Check what features were created\nfeatures = catalog.get_features()\nprint(f\"Created {features.shape[1]} features from {features.shape[0]} objects\")\n</code></pre>"},{"location":"getting-started/#using-pre-trained-models","title":"Using Pre-trained Models","text":"<p>AGNBoost comes with pre-trained models for common astronomical tasks:</p> <pre><code>from agnboost import AGNBoost\n\n# Initialize AGNBoost\nagnboost = AGNBoost()\n\n# Load pre-trained models\nmodels_loaded = agnboost.load_models()\n\nif models_loaded:\n    print(\"Pre-trained models loaded successfully!\")\n\n    # Make predictions\n    predictions = agnboost.predict(catalog)\n    print(\"Available predictions:\", list(predictions.keys()))\nelse:\n    print(\"No pre-trained models found. You may need to train new models.\")\n</code></pre>"},{"location":"getting-started/#a-complete-example","title":"A Complete Example","text":"<p>Here's a complete workflow from data loading to predictions:</p> <pre><code>from agnboost import Catalog, AGNBoost\n\n# Step 1: Load your data\ncatalog = Catalog(path=\"jwst_photometry.fits\")\nprint(f\"Loaded {len(catalog.get_data())} astronomical objects\")\n\n# Step 2: Create features\ncatalog.create_feature_dataframe()\nprint(f\"Generated {catalog.get_features().shape[1]} features\")\n\n# Step 3: Load pre-trained models\nagnboost = AGNBoost()\nagnboost.load_models()\n\n# Step 4: Make predictions\npredictions = agnboost.predict(catalog)\n\n# Step 5: Access your results\nfor model_name, preds in predictions.items():\n    print(f\"Predictions from {model_name} model: {len(preds)} objects\")\n</code></pre>"},{"location":"getting-started/#data-requirements","title":"Data Requirements","text":"<p>For AGNBoost to work optimally, your data should include:</p> <ul> <li>Photometric measurements: Flux or magnitude values in supported bands</li> <li>Error estimates: Uncertainty values for photometric measurements  </li> <li>Valid band names: Column names that match the <code>allowed_bands.json</code> configuration</li> </ul> <p>You can check which bands are recognized:</p> <pre><code># See which photometric bands were found in your data\nvalid_bands = catalog.get_valid_bands()\nprint(\"Valid photometric bands found:\")\nfor band_name, info in valid_bands.items():\n    print(f\"  {band_name}: {info['shorthand']} ({info['wavelength']} \u03bcm)\")\n</code></pre>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<p>Now that you have the basics working, you can:</p> <ul> <li>Explore the tutorials: Learn about advanced features and customization</li> <li>Check the API documentation: Deep dive into all available methods and options</li> <li>Train custom models: Use your own data to train specialized models</li> </ul>"},{"location":"getting-started/#useful-links","title":"Useful Links","text":"<ul> <li>Band Configuration Tutorial - Learn how to add new photometric bands</li> <li>Training from Scratch Tutorial - Train models on your own data</li> <li>API Reference - Complete documentation of all classes and methods</li> </ul>"},{"location":"getting-started/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/#common-issues","title":"Common Issues","text":"<p>\"No valid band columns found\": Your data column names don't match the expected photometric band names. Check the Band Configuration Tutorial to learn how to add your bands.</p> <p>\"No pre-trained models found\": The models directory is empty or models are incompatible. You may need to train new models or check that the models were properly downloaded.</p> <p>Import errors: Make sure all dependencies are installed. See the Installation guide for details.</p>"},{"location":"getting-started/#getting-help","title":"Getting Help","text":"<p>If you encounter issues:</p> <ol> <li>Check the API documentation for detailed method descriptions</li> <li>Look at the tutorial examples for similar use cases</li> <li>Open an issue on the GitHub repository</li> </ol>"},{"location":"tutorials/basic-usage/","title":"AGNBoost Basic Usage Tutorial","text":"In\u00a0[1]: Copied! <pre>%load_ext autoreload\n%autoreload 2\n</pre> %load_ext autoreload %autoreload 2 In\u00a0[2]: Copied! <pre># Set agnbioost folder as root\nimport os\nos.chdir(os.path.expanduser(\"/home/kurt/Documents/agnboost/\"))\n\n# Import necessary libraries\nimport numpy as np\nimport pandas as pd\nfrom agnboost import dataset, model\n#from sklearn.metrics import mean_squared_error\n\n# Set random seed for reproducibility\nnp.random.seed(123)\n\nprint(\"AGNBoost Basic Usage Tutorial\")\nprint(\"=\" * 40)\n</pre> # Set agnbioost folder as root import os os.chdir(os.path.expanduser(\"/home/kurt/Documents/agnboost/\"))  # Import necessary libraries import numpy as np import pandas as pd from agnboost import dataset, model #from sklearn.metrics import mean_squared_error  # Set random seed for reproducibility np.random.seed(123)  print(\"AGNBoost Basic Usage Tutorial\") print(\"=\" * 40) <pre>2025-05-25 16:36:50.131 | INFO     | agnboost.config:&lt;module&gt;:11 - PROJ_ROOT path is: /home/kurt/Documents/agnboost\n</pre> <pre>AGNBoost Basic Usage Tutorial\n========================================\n</pre> In\u00a0[25]: Copied! <pre># Load the astronomical data using the Catalog class\ncatalog = dataset.Catalog(path=\"data/cigale_mock_small.csv\",summarize = False)\n</pre> # Load the astronomical data using the Catalog class catalog = dataset.Catalog(path=\"data/cigale_mock_small.csv\",summarize = False)  <pre>Current working directory: /home/kurt/Documents/agnboost\nLooking for bands file at: /home/kurt/Documents/agnboost/allowed_bands.json\n[INFO] Loaded bands file metadata: This file contains the allowed photometric bands for JWST\n[INFO] Loaded 11 allowed bands from agnboost/allowed_bands.json\n[INFO] Attempting to load file with delimiter: ','\n[INFO] Successfully loaded data with 1000 rows.\n[INFO] Found 11 valid band columns:\n[INFO]   - jwst.nircam.F115W (F115W): 1.154 \u03bcm\n[INFO]   - jwst.nircam.F150W (F150W): 1.501 \u03bcm\n[INFO]   - jwst.nircam.F200W (F200W): 1.988 \u03bcm\n[INFO]   - jwst.nircam.F277W (F277W): 2.776 \u03bcm\n[INFO]   - jwst.nircam.F356W (F356W): 3.565 \u03bcm\n[INFO]   - jwst.nircam.F410M (F410M): 4.083 \u03bcm\n[INFO]   - jwst.nircam.F444W (F444W): 4.402 \u03bcm\n[INFO]   - jwst.miri.F770W (F770W): 7.7 \u03bcm\n[INFO]   - jwst.miri.F1000W (F1000W): 10.0 \u03bcm\n[INFO]   - jwst.miri.F1500W (F1500W): 15.0 \u03bcm\n[INFO]   - jwst.miri.F2100W (F2100W): 21.0 \u03bcm\n</pre> In\u00a0[26]: Copied! <pre># Display comprehensive data summary\ncatalog.print_data_summary()\n\n# Check which photometric bands were validated\nvalid_bands = catalog.get_valid_bands()\nprint(f\"\\nValid photometric bands found: {len(valid_bands)}\")\nfor band_name, info in valid_bands.items():\n    print(f\"  {band_name}: {info['shorthand']} ({info['wavelength']} \u03bcm)\")\n\n# Check if our target variable exists\ntarget_column = 'agn.fracAGN'\nif target_column in catalog.get_data().columns:\n    print(f\"\\nTarget variable '{target_column}' found in dataset\")\n    target_stats = catalog.get_data()[target_column].describe()\n    print(\"Target variable statistics:\")\n    print(target_stats)\nelse:\n    print(f\"Warning: Target variable '{target_column}' not found in dataset\")\n    print(\"Available columns:\", list(catalog.get_data().columns))\n</pre> # Display comprehensive data summary catalog.print_data_summary()  # Check which photometric bands were validated valid_bands = catalog.get_valid_bands() print(f\"\\nValid photometric bands found: {len(valid_bands)}\") for band_name, info in valid_bands.items():     print(f\"  {band_name}: {info['shorthand']} ({info['wavelength']} \u03bcm)\")  # Check if our target variable exists target_column = 'agn.fracAGN' if target_column in catalog.get_data().columns:     print(f\"\\nTarget variable '{target_column}' found in dataset\")     target_stats = catalog.get_data()[target_column].describe()     print(\"Target variable statistics:\")     print(target_stats) else:     print(f\"Warning: Target variable '{target_column}' not found in dataset\")     print(\"Available columns:\", list(catalog.get_data().columns)) <pre>\n================================================================================\nDATA SUMMARY: cigale_mock_small.csv\n================================================================================\nDimensions: 1000 rows \u00d7 26 columns\nMemory usage: 0.20 MB\n--------------------------------------------------------------------------------\nValid Band Columns:\n--------------------------------------------------------------------------------\nColumn Name                    Shorthand       Wavelength (\u03bcm)\n--------------------------------------------------------------------------------\njwst.nircam.F115W              F115W           1.154          \njwst.nircam.F150W              F150W           1.501          \njwst.nircam.F200W              F200W           1.988          \njwst.nircam.F277W              F277W           2.776          \njwst.nircam.F356W              F356W           3.565          \njwst.nircam.F410M              F410M           4.083          \njwst.nircam.F444W              F444W           4.402          \njwst.miri.F770W                F770W           7.700          \njwst.miri.F1000W               F1000W          10.000         \njwst.miri.F1500W               F1500W          15.000         \njwst.miri.F2100W               F2100W          21.000         \n--------------------------------------------------------------------------------\nColumn Information:\n--------------------------------------------------------------------------------\nColumn Name                    Type            Non-Null        Null %    \n--------------------------------------------------------------------------------\nIRAC1                          float64         1000/1000            0.00%     \nIRAC2                          float64         1000/1000            0.00%     \nIRAC3                          float64         1000/1000            0.00%     \nIRAC4                          float64         1000/1000            0.00%     \nhst.acs.wfc.F606W              float64         1000/1000            0.00%     \nhst.acs.wfc.F814W              float64         1000/1000            0.00%     \nhst.wfc3.ir.F125W              float64         1000/1000            0.00%     \nhst.wfc3.ir.F140W              float64         1000/1000            0.00%     \nhst.wfc3.ir.F160W              float64         1000/1000            0.00%     \njwst.miri.F1000W               float64         1000/1000            0.00%     \njwst.miri.F1280W               float64         1000/1000            0.00%     \njwst.miri.F1500W               float64         1000/1000            0.00%     \njwst.miri.F1800W               float64         1000/1000            0.00%     \njwst.miri.F2100W               float64         1000/1000            0.00%     \njwst.miri.F770W                float64         1000/1000            0.00%     \njwst.nircam.F115W              float64         1000/1000            0.00%     \njwst.nircam.F150W              float64         1000/1000            0.00%     \njwst.nircam.F200W              float64         1000/1000            0.00%     \njwst.nircam.F277W              float64         1000/1000            0.00%     \njwst.nircam.F356W              float64         1000/1000            0.00%     \njwst.nircam.F410M              float64         1000/1000            0.00%     \njwst.nircam.F444W              float64         1000/1000            0.00%     \nsfh.sfr100Myrs                 float64         1000/1000            0.00%     \nstellar.m_star                 float64         1000/1000            0.00%     \nagn.fracAGN                    float64         1000/1000            0.00%     \nuniverse.redshift              float64         1000/1000            0.00%     \n--------------------------------------------------------------------------------\n\nNumeric Column Statistics:\n--------------------------------------------------------------------------------\nColumn                         Mean         Std          Min          Max         \n--------------------------------------------------------------------------------\nIRAC1                57.9         1308         2.413e-06    4.098e+04   \nIRAC2                22.97        509.9        8.821e-07    1.596e+04   \nIRAC3                39.96        918          1.646e-06    2.879e+04   \nIRAC4                57.92        1309         2.413e-06    4.099e+04   \nhst.acs.wfc.F606W    0.311        5.52         0            169         \nhst.acs.wfc.F814W    0.3093       5.099        5.455e-13    155.8       \nhst.wfc3.ir.F125W    0.5148       6.576        1.614e-09    192.2       \nhst.wfc3.ir.F140W    0.6132       7.125        2.611e-09    196.7       \nhst.wfc3.ir.F160W    0.7412       7.991        4.119e-09    200.2       \njwst.miri.F1000W     57.54        1356         3.049e-06    4.257e+04   \njwst.miri.F1280W     71.4         1587         4.006e-06    4.97e+04    \njwst.miri.F1500W     74.16        1638         4.475e-06    5.129e+04   \njwst.miri.F1800W     82.2         1710         4.232e-06    5.339e+04   \njwst.miri.F2100W     87.79        1773         4.001e-06    5.527e+04   \njwst.miri.F770W      58.58        1315         2.288e-06    4.117e+04   \njwst.nircam.F115W    0.461        6.317        1.192e-09    188.6       \njwst.nircam.F150W    0.706        7.721        3.693e-09    198.7       \njwst.nircam.F200W    1.482        15.31        1.959e-08    280.6       \njwst.nircam.F277W    4.441        68.46        1.332e-07    2009        \njwst.nircam.F356W    11.62        225.3        4.48e-07     6973        \njwst.nircam.F410M    17.51        373          6.242e-07    1.164e+04   \njwst.nircam.F444W    21.65        477          8.29e-07     1.492e+04   \nsfh.sfr100Myrs       4.765        4.403        4.765e-27    15.79       \nstellar.m_star       3.51e+09     2.551e+09    3.367e+07    7.388e+09   \nagn.fracAGN          0.4993       0.3164       0            0.99        \nuniverse.redshift    1.765        1.811        0.01         7.999       \n================================================================================\n\n\nValid photometric bands found: 11\n  jwst.nircam.F115W: F115W (1.154 \u03bcm)\n  jwst.nircam.F150W: F150W (1.501 \u03bcm)\n  jwst.nircam.F200W: F200W (1.988 \u03bcm)\n  jwst.nircam.F277W: F277W (2.776 \u03bcm)\n  jwst.nircam.F356W: F356W (3.565 \u03bcm)\n  jwst.nircam.F410M: F410M (4.083 \u03bcm)\n  jwst.nircam.F444W: F444W (4.402 \u03bcm)\n  jwst.miri.F770W: F770W (7.7 \u03bcm)\n  jwst.miri.F1000W: F1000W (10.0 \u03bcm)\n  jwst.miri.F1500W: F1500W (15.0 \u03bcm)\n  jwst.miri.F2100W: F2100W (21.0 \u03bcm)\n\nTarget variable 'agn.fracAGN' found in dataset\nTarget variable statistics:\ncount    1000.000000\nmean        0.499330\nstd         0.316352\nmin         0.000000\n25%         0.200000\n50%         0.500000\n75%         0.800000\nmax         0.990000\nName: agn.fracAGN, dtype: float64\n</pre> In\u00a0[27]: Copied! <pre># Create train/validation/test splitsget_train_val_test_sizes\ncatalog.split_data(test_size=0.2, val_size=0.2, random_state=42)\n\n# Get split information\nsplit_info = catalog.get_train_val_test_sizes()\nprint(\"Data split summary:\")\nprint(f\"  Total samples: {split_info['total']}\")\nprint(f\"  Training: {split_info['train']['size']} ({split_info['train']['percentage']:.1f}%)\")\nprint(f\"  Validation: {split_info['validation']['size']} ({split_info['validation']['percentage']:.1f}%)\")\nprint(f\"  Test: {split_info['test']['size']} ({split_info['test']['percentage']:.1f}%)\")\n</pre> # Create train/validation/test splitsget_train_val_test_sizes catalog.split_data(test_size=0.2, val_size=0.2, random_state=42)  # Get split information split_info = catalog.get_train_val_test_sizes() print(\"Data split summary:\") print(f\"  Total samples: {split_info['total']}\") print(f\"  Training: {split_info['train']['size']} ({split_info['train']['percentage']:.1f}%)\") print(f\"  Validation: {split_info['validation']['size']} ({split_info['validation']['percentage']:.1f}%)\") print(f\"  Test: {split_info['test']['size']} ({split_info['test']['percentage']:.1f}%)\") <pre>Data split summary:\n  Total samples: 1000\n  Training: 600 (60.0%)\n  Validation: 200 (20.0%)\n  Test: 200 (20.0%)\n</pre> In\u00a0[28]: Copied! <pre># Drop rows with NaN values in the validated columns\ncatalog.drop_nan(inplace=True)\n</pre> # Drop rows with NaN values in the validated columns catalog.drop_nan(inplace=True)  <pre>[INFO] No rows with NaN values found in the specified columns.\n</pre> In\u00a0[29]: Copied! <pre># Create features for modeling\ncatalog.create_feature_dataframe()\n\n# Get information about created features\nfeatures = catalog.get_features()\nprint(f\"Feature engineering complete:\")\nprint(f\"  Feature dataframe shape: {features.shape}\")\n</pre> # Create features for modeling catalog.create_feature_dataframe()  # Get information about created features features = catalog.get_features() print(f\"Feature engineering complete:\") print(f\"  Feature dataframe shape: {features.shape}\")  <pre>[INFO] Created feature dataframe with 121 columns and 1000 rows.\nFeature engineering complete:\n  Feature dataframe shape: (1000, 121)\n</pre> In\u00a0[30]: Copied! <pre># Initialize AGNBoost with the target model\nagnboost_m = model.AGNBoost( feature_names = catalog.get_feature_names(),\n                          target_variables = {'agn.fracAGN' : 'ZABeta'},\n                         )\n\n# Load pre-trained models\nfilename = '2025_05_22-PM06_59_58_agn.fracAGN_model.pkl.gz'\nagnboost_m.load_model(file_name = filename, overwrite = True)\nprint(agnboost_m.models)\n\nif agnboost_m.models['agn.fracAGN'] is not None:\n    print(\"\u2705 Pre-trained model loaded successfully!\")\n    \n    # Display model information\n    model_info = agnboost_m.model_info.get('agn.fracAGN', {})\n    if model_info:\n        print(\"\\nModel information:\")\n        if 'training_timestamp' in model_info:\n            print(f\"  Trained: {model_info['training_timestamp']}\")\n        if 'best_score' in model_info:\n            print(f\"  Best validation score: {model_info['best_score']:.6f}\")\n        if 'features' in model_info:\n            print(f\"  Number of features: {len(model_info['features'])}\")\nelse:\n    print(\"\u274c No pre-trained models found!\")\n    print(\"You may need to train a new model or check the models directory.\")\n</pre> # Initialize AGNBoost with the target model agnboost_m = model.AGNBoost( feature_names = catalog.get_feature_names(),                           target_variables = {'agn.fracAGN' : 'ZABeta'},                          )  # Load pre-trained models filename = '2025_05_22-PM06_59_58_agn.fracAGN_model.pkl.gz' agnboost_m.load_model(file_name = filename, overwrite = True) print(agnboost_m.models)  if agnboost_m.models['agn.fracAGN'] is not None:     print(\"\u2705 Pre-trained model loaded successfully!\")          # Display model information     model_info = agnboost_m.model_info.get('agn.fracAGN', {})     if model_info:         print(\"\\nModel information:\")         if 'training_timestamp' in model_info:             print(f\"  Trained: {model_info['training_timestamp']}\")         if 'best_score' in model_info:             print(f\"  Best validation score: {model_info['best_score']:.6f}\")         if 'features' in model_info:             print(f\"  Number of features: {len(model_info['features'])}\") else:     print(\"\u274c No pre-trained models found!\")     print(\"You may need to train a new model or check the models directory.\") <pre>{'agn.fracAGN': &lt;xgboostlss.model.XGBoostLSS object at 0x7905e74b1090&gt;}\n\u2705 Pre-trained model loaded successfully!\n\nModel information:\n  Best validation score: -649218.125000\n  Number of features: 121\n</pre> In\u00a0[31]: Copied! <pre># Make predictions on the test set\n#agnboost_m.models['agn.fracAGN'].booster.set_param( {'device': 'cpu'})\npreds = agnboost_m.predict( data = catalog, split_use = 'test', model_name = 'agn.fracAGN')\n\nprint(f\"  Mean: {np.mean(preds):.6f}\")\nprint(f\"  Std: {np.std(preds):.6f}\")\nprint(f\"  Min: {np.min(preds):.6f}\")\nprint(f\"  Max: {np.max(preds):.6f}\")\n</pre> # Make predictions on the test set #agnboost_m.models['agn.fracAGN'].booster.set_param( {'device': 'cpu'}) preds = agnboost_m.predict( data = catalog, split_use = 'test', model_name = 'agn.fracAGN')  print(f\"  Mean: {np.mean(preds):.6f}\") print(f\"  Std: {np.std(preds):.6f}\") print(f\"  Min: {np.min(preds):.6f}\") print(f\"  Max: {np.max(preds):.6f}\")  <pre>2025-05-25 17:01:36,708 - AGNBoost.AGNBoost - WARNING - Catalog object passsed. Taking the features and labels of the test set stored in the passed Catalog.\n</pre> <pre>  Mean: 0.504962\n  Std: 0.325251\n  Min: 0.000308\n  Max: 0.989859\n</pre> In\u00a0[32]: Copied! <pre>model_uncertainty = agnboost_m.prediction_uncertainty( uncertainty_type = 'model', model_name = 'agn.fracAGN', catalog = catalog)\n\nprint(f\"\u2705 Uncertainty estimates generated\")\nprint(f\"Uncertainty statistics:\")\nprint(f\"  Mean uncertainty: {np.mean(model_uncertainty):.6f}\")\nprint(f\"  Std uncertainty: {np.std(model_uncertainty):.6f}\")\nprint(f\"  Min uncertainty: {np.min(model_uncertainty):.6f}\")\nprint(f\"  Max uncertainty: {np.max(model_uncertainty):.6f}\")\n</pre> model_uncertainty = agnboost_m.prediction_uncertainty( uncertainty_type = 'model', model_name = 'agn.fracAGN', catalog = catalog)  print(f\"\u2705 Uncertainty estimates generated\") print(f\"Uncertainty statistics:\") print(f\"  Mean uncertainty: {np.mean(model_uncertainty):.6f}\") print(f\"  Std uncertainty: {np.std(model_uncertainty):.6f}\") print(f\"  Min uncertainty: {np.min(model_uncertainty):.6f}\") print(f\"  Max uncertainty: {np.max(model_uncertainty):.6f}\") <pre>2025-05-25 17:01:39,333 - AGNBoost.AGNBoost - WARNING - Catalog object passsed. Taking the features and labels of the None set stored in the passed Catalog.\nProcessing truncated model uncertainty: 100%|\u2588| 1000/1000 [07:09&lt;00:00,  2.33it/</pre> <pre>\u2705 Uncertainty estimates generated\nUncertainty statistics:\n  Mean uncertainty: 0.033900\n  Std uncertainty: 0.013166\n  Min uncertainty: 0.000940\n  Max uncertainty: 0.071419\n</pre> <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"tutorials/basic-usage/#agnboost-basic-usage-tutorial","title":"AGNBoost Basic Usage Tutorial\u00b6","text":"<p>This notebook demonstrates the basic workflow for using AGNBoost to predict AGN fractions from photometric data. We'll walk through:</p> <ol> <li>Loading astronomical data with the Catalog class</li> <li>Exploring the dataset structure and properties</li> <li>Splitting data into training, validation, and test sets</li> <li>Cleaning the data by removing rows with missing values</li> <li>Loading a pre-trained AGN fraction model</li> <li>Making predictions with uncertainty quantification</li> <li>Evaluating model performance</li> </ol> <p>Let's start by importing the necessary libraries and loading our data.</p>"},{"location":"tutorials/basic-usage/#loading-the-data","title":"Loading the Data\u00b6","text":"<p>We'll use the Catalog class to load our astronomical dataset. The <code>models-block-0.fits</code> file contains photometric measurements and AGN fraction labels for our analysis.</p>"},{"location":"tutorials/basic-usage/#exploring-the-dataset","title":"Exploring the Dataset\u00b6","text":"<p>Let's examine the structure of our data to understand what photometric bands are available and get basic statistics about our dataset. The <code>print_data_summary()</code> method provides comprehensive information about:</p> <ul> <li>Dataset dimensions and memory usage</li> <li>Photometric band validation and metadata</li> <li>Column-by-column statistics including missing values</li> <li>Summary statistics for numerical columns</li> </ul> <p>This information helps us understand data quality and identify any potential issues before modeling.</p>"},{"location":"tutorials/basic-usage/#creating-traintestvalidation-splits","title":"Creating Train/Test/Validation Splits\u00b6","text":"<p>Before any modeling, we need to split our data into separate sets for training, validation, and testing. AGNBoost provides intelligent data splitting with optional stratification to ensure representative samples across all splits.</p> <p>We'll use the default split ratios:</p> <ul> <li>60% for training</li> <li>20% for validation</li> <li>20% for testing</li> </ul> <p>The random state ensures reproducible results.</p>"},{"location":"tutorials/basic-usage/#cleaning-the-data","title":"Cleaning the Data\u00b6","text":"<p>Real astronomical datasets often contain missing values due to various observational limitations. Before training or making predictions, we will remove rows that have NaN values in critical columns.</p> <p>The <code>drop_nan()</code> method removes rows with missing values in the validated photometric band columns, ensuring our model receives complete data for all features.</p>"},{"location":"tutorials/basic-usage/#creating-features","title":"Creating Features\u00b6","text":"<p>AGNBoost automatically engineers features from photometric data, including colors and transformations. Let's create the feature dataframe that will be used for modeling.</p> <p>By default, AGNBoost will create a features consisting of the photometric bands + derived colors + the squares of those derived colors</p>"},{"location":"tutorials/basic-usage/#loading-the-pre-trained-model","title":"Loading the Pre-trained Model\u00b6","text":"<p>AGNBoost comes with pre-trained models for common astronomical tasks. We'll load the model specifically trained for AGN fraction estimation (<code>agn.fracAGN</code>).</p> <p>The <code>load_models()</code> method automatically:</p> <ul> <li>Checks for compatible pre-trained models</li> <li>Validates feature compatibility between the model and our data</li> <li>Loads model metadata including training parameters and performance metrics</li> </ul>"},{"location":"tutorials/basic-usage/#making-predictions","title":"Making Predictions\u00b6","text":"<p>Now we'll use our loaded model to predict AGN fractions for the test set. AGNBoost seamlessly handles the conversion of our catalog data into the format required by the underlying XGBoost model.</p> <p>The prediction process uses the engineered features (colors, log magnitudes, etc.) that were automatically created from our photometric band data.</p>"},{"location":"tutorials/basic-usage/#quantifying-prediction-uncertainty","title":"Quantifying Prediction Uncertainty\u00b6","text":"<p>One of AGNBoost's key advantages is its ability to provide robust uncertainty estimates through XGBoostLSS distributional modeling. Rather than just point estimates, we get full uncertainty quantification for each prediction.</p> <p>The <code>prediction_uncertainty()</code> method returns uncertainty estimates that account for both model uncertainty and the inherent variability in the data. This is crucial for astronomical applications where understanding prediction confidence is essential for scientific interpretation.</p> <p>Since the loaded data is a CIGALE mock catalog with no photometric uncertainty, we will only estimate the model (aleatoric + epistemic) uncertainty for each source.</p>"}]}